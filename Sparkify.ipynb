{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify Project Workspace\n",
    "This workspace contains a tiny subset (128MB) of the full dataset available (12GB). Feel free to use this workspace to build your project, or to explore a smaller subset with Spark before deploying your cluster on the cloud. Instructions for setting up your Spark cluster is included in the last lesson of the Extracurricular Spark Course content.\n",
    "\n",
    "You can follow the steps below to guide your data analysis and model building portion of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notation\n",
    "\n",
    "In this notebook we refer to the mini_sparkify_event_data.json as the total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "from pyspark.sql.functions import udf, col, lit, min as Fmin, max as Fmax, sum as Fsum, expr\n",
    "from pyspark.sql.types import IntegerType, DateType, FloatType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "\n",
    "configure = SparkConf() \\\n",
    "    .setAppName(\"ml_pipelines\") \\\n",
    "    .setMaster(\"local\") \\\n",
    "    .set('spark.executor.memory', '6g') \\\n",
    "    .set('spark.driver.memory', '4g') \\\n",
    "    .set('spark.executor.instances', '1') \\\n",
    "    .set('spark.driver.cores', '2')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .config(conf=configure) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Dataset\n",
    "In this workspace, the mini-dataset file is `mini_sparkify_event_data.json`. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('mini_sparkify_event_data.json')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[artist: string, auth: string, firstName: string, gender: string, itemInSession: bigint, lastName: string, length: double, level: string, location: string, method: string, page: string, registration: bigint, sessionId: bigint, song: string, status: bigint, ts: bigint, userAgent: string, userId: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286500\n"
     ]
    }
   ],
   "source": [
    "# Before checking for null values, lets get a sense of the size of the dataset\n",
    "\n",
    "dataset_size = df.count()\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in userId and sessionId\n",
    "print( df.where(col(\"userId\").isNull()).count() )\n",
    "print( df.where(col(\"sessionId\").isNull()).count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8346\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check for empty strings in userId and sessionId\n",
    "print( df.where(col(\"userId\") == \"\").count() )\n",
    "print( df.where(col(\"sessionId\") == \"\").count() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8346 records where the userId is null. This is 2.9% of the total dataset ( mini_sparkify.json ). Lets remove these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.userId != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nulls in other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist : 50046 : 0.1746806282722513\n",
      "auth : 0 : 0.0\n",
      "firstName : 0 : 0.0\n",
      "gender : 0 : 0.0\n",
      "itemInSession : 0 : 0.0\n",
      "lastName : 0 : 0.0\n",
      "length : 50046 : 0.1746806282722513\n",
      "level : 0 : 0.0\n",
      "location : 0 : 0.0\n",
      "method : 0 : 0.0\n",
      "page : 0 : 0.0\n",
      "registration : 0 : 0.0\n",
      "sessionId : 0 : 0.0\n",
      "song : 50046 : 0.1746806282722513\n",
      "status : 0 : 0.0\n",
      "ts : 0 : 0.0\n",
      "userAgent : 0 : 0.0\n",
      "userId : 0 : 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in df.columns:\n",
    "    null_count_c = df.where(col(c).isNull()).count()\n",
    "    proportion_null = null_count_c/dataset_size\n",
    "    print( c + ' : ' + str(null_count_c) + ' : ' + str(proportion_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only artist, length and song seem to have nulls and also to the exact same extent. The values are likely null for page visits which dont involve a song like the home page etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "When you're working with the full dataset, perform EDA by loading a small subset of the data and doing basic manipulations within Spark. In this workspace, you are already provided a small subset of data you can explore.\n",
    "\n",
    "### Define Churn\n",
    "\n",
    "Once you've done some preliminary analysis, create a column `Churn` to use as the label for your model. I suggest using the `Cancellation Confirmation` events to define your churn, which happen for both paid and free users. As a bonus task, you can also look into the `Downgrade` events.\n",
    "\n",
    "### Explore Data\n",
    "Once you've defined churn, perform some exploratory data analysis to observe the behavior for users who stayed vs users who churned. You can start by exploring aggregates on these two groups of users, observing how much of a specific action they experienced per a certain time unit or number of songs played."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic understanding of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Martha Tilston', auth='Logged In', firstName='Colin', gender='M', itemInSession=50, lastName='Freeman', length=277.89016, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Rockpools', status=200, ts=1538352117000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30'),\n",
       " Row(artist='Five Iron Frenzy', auth='Logged In', firstName='Micah', gender='M', itemInSession=79, lastName='Long', length=236.09424, level='free', location='Boston-Cambridge-Newton, MA-NH', method='PUT', page='NextSong', registration=1538331630000, sessionId=8, song='Canada', status=200, ts=1538352180000, userAgent='\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.103 Safari/537.36\"', userId='9')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at 2 rows\n",
    "\n",
    "df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min timestamp = Mon Oct  1 00:01:57 2018\n",
      "Max timestamp = Mon Dec  3 01:11:16 2018\n"
     ]
    }
   ],
   "source": [
    "# Timespan of the data\n",
    "\n",
    "print( 'Min timestamp = ' + str( datetime.datetime.utcfromtimestamp( df.agg(Fmin(col(\"ts\"))).collect()[0][0]/1000  ).strftime('%c') ) )\n",
    "print( 'Max timestamp = ' + str( datetime.datetime.utcfromtimestamp( df.agg(Fmax(col(\"ts\"))).collect()[0][0]/1000  ).strftime('%c') ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In UTC the data given is from 1-Oct-2018 to the early hours of 3-Dec-2018.\n",
    "\n",
    "Effectively the data given is for a period of 2 months ( 63 days to be precise )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of users\n",
    "\n",
    "df.select(\"userId\").dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2312"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of sessions\n",
    "\n",
    "df.select(\"sessionId\").dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth\n",
      "+---------+------+\n",
      "|auth     |count |\n",
      "+---------+------+\n",
      "|Logged In|278102|\n",
      "|Cancelled|52    |\n",
      "+---------+------+\n",
      "\n",
      "gender\n",
      "+------+------+\n",
      "|gender|count |\n",
      "+------+------+\n",
      "|F     |154578|\n",
      "|M     |123576|\n",
      "+------+------+\n",
      "\n",
      "level\n",
      "+-----+------+\n",
      "|level|count |\n",
      "+-----+------+\n",
      "|paid |222433|\n",
      "|free |55721 |\n",
      "+-----+------+\n",
      "\n",
      "method\n",
      "+------+------+\n",
      "|method|count |\n",
      "+------+------+\n",
      "|PUT   |257818|\n",
      "|GET   |20336 |\n",
      "+------+------+\n",
      "\n",
      "page\n",
      "+-------------------------+------+\n",
      "|page                     |count |\n",
      "+-------------------------+------+\n",
      "|NextSong                 |228108|\n",
      "|Thumbs Up                |12551 |\n",
      "|Home                     |10082 |\n",
      "|Add to Playlist          |6526  |\n",
      "|Add Friend               |4277  |\n",
      "|Roll Advert              |3933  |\n",
      "|Logout                   |3226  |\n",
      "|Thumbs Down              |2546  |\n",
      "|Downgrade                |2055  |\n",
      "|Settings                 |1514  |\n",
      "|Help                     |1454  |\n",
      "|Upgrade                  |499   |\n",
      "|About                    |495   |\n",
      "|Save Settings            |310   |\n",
      "|Error                    |252   |\n",
      "|Submit Upgrade           |159   |\n",
      "|Submit Downgrade         |63    |\n",
      "|Cancel                   |52    |\n",
      "|Cancellation Confirmation|52    |\n",
      "+-------------------------+------+\n",
      "\n",
      "status\n",
      "+------+------+\n",
      "|status|count |\n",
      "+------+------+\n",
      "|200   |254718|\n",
      "|307   |23184 |\n",
      "|404   |252   |\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distinct values taken by different categorical variables at the app level and their respective number of occurences in the data\n",
    "\n",
    "# The following fields are excluded here since they are user activity specific. serId, sessionId, artist\n",
    "\n",
    "categorical_variables = [ 'auth' , 'gender', 'level', 'method', 'page', 'status' ]\n",
    "\n",
    "for cvar in categorical_variables:\n",
    "    print(cvar)\n",
    "#     df.select(cvar).dropDuplicates().sort(cvar).show(100, False)\n",
    "    df.groupby(cvar).count().sort('count', ascending = False).show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the status field the 404's are interesting and could potentially have a correlation with users dropping out\n",
    "\n",
    "Most of our events seem to be for listening to the next song\n",
    "\n",
    "The GET requests are likely for Home page visits etc.\n",
    "\n",
    "Most events are from paid users\n",
    "\n",
    "auth=Cancelled seems to refer to users who have cancelled their subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num songs: 58481\n",
      "Num artists: 17656\n"
     ]
    }
   ],
   "source": [
    "# Number of songs and artists\n",
    "\n",
    "print( 'Num songs: ' + str(df.select(\"song\").drop_duplicates().count()))\n",
    "print( 'Num artists: ' + str(df.select(\"artist\").drop_duplicates().count()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining churn\n",
    "\n",
    "We define churn as a user cancelling their service. If we see a \"Cancellation Confirmation\" event for a user, then we would consider that user to have churned\n",
    "\n",
    "Given our definition of churn, downgrades of service from paid to free tier could be potential indicators of churn too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = udf(lambda x: int(x == 'Cancellation Confirmation'), IntegerType())\n",
    "downgrade_churn = udf(lambda x: int(x == 'Submit Downgrade'), IntegerType())\n",
    "\n",
    "df = df.withColumn(\"downgraded\", downgrade_churn(\"page\")).withColumn(\"cancelled\", churn(\"page\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compute the number of users who downgraded or cancelled\n",
    "\n",
    "# We first compute the status of each user\n",
    "signum = udf(lambda x: int(x>0), IntegerType())\n",
    "# The signum function is used since there are users who have multiple downgrade events.\n",
    "\n",
    "user_status = df.select([\"userId\", \"downgraded\", \"cancelled\"]) \\\n",
    "    .groupby(\"userId\").sum() \\\n",
    "    .withColumnRenamed(\"sum(downgraded)\" , \"sum_downgraded\") \\\n",
    "    .withColumnRenamed(\"sum(cancelled)\" , \"sum_cancelled\") \\\n",
    "\n",
    "user_status = user_status \\\n",
    "    .withColumn('downgraded', signum(col(\"sum_downgraded\"))) \\\n",
    "    .withColumn('cancelled', signum(col(\"sum_cancelled\"))) \\\n",
    "    .drop('sum_downgraded').drop('sum_cancelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+\n",
      "|userId|downgraded|cancelled|\n",
      "+------+----------+---------+\n",
      "|100010|         0|        0|\n",
      "|200002|         0|        0|\n",
      "|   125|         0|        1|\n",
      "|    51|         0|        1|\n",
      "|   124|         0|        0|\n",
      "|     7|         0|        0|\n",
      "|    54|         1|        1|\n",
      "|    15|         0|        0|\n",
      "|   155|         0|        0|\n",
      "|   132|         0|        0|\n",
      "+------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_status.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its interesting that userId 54 both downgraded and cancelled. Some users seem to have directly cancelled without downgrading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+\n",
      "|sum(downgraded)|sum(cancelled)|\n",
      "+---------------+--------------+\n",
      "|             49|            52|\n",
      "+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_status.agg({ 'downgraded' : 'sum', 'cancelled': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 49 users who downgraded and 52 who cancelled\n",
    "\n",
    "One must keep in mind that the total number of users is 225. This means 21.7% of users downgraded and 23% cancelled. These numbers are quite high, hence its imperative that we identify these users upfront, address their needs and incentivise them to stay on the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|level|count|\n",
      "+-----+-----+\n",
      "| free|   21|\n",
      "| paid|   31|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Of the users who cancelled whats the split of tier of service ( paid/free )\n",
    "\n",
    "df.filter(df.page == 'Cancellation Confirmation').select([\"userId\", \"level\"]).drop_duplicates().groupby(\"level\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 52 who cancelled, 21 are free and 31 are paid users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|downgraded|count|\n",
      "+----------+-----+\n",
      "|         1|    9|\n",
      "|         0|   43|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many users cancelled without downgrading\n",
    "\n",
    "user_status.where(col(\"cancelled\") == 1).groupby(\"downgraded\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 52 users who cancelled, 43 of them directly cancelled and only 9 of them downgraded before cancelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marking the time and phase of churn for each user\n",
    "# This will help us find metrics before and after churn for users\n",
    "\n",
    "\n",
    "window = Window().partitionBy(\"userId\").orderBy(\"ts\").rangeBetween(Window.unboundedPreceding, 0)\n",
    "df = df.withColumn(\"churn_phase\", Fsum(\"cancelled\").over(window)).withColumn(\"downgrade_phase\", Fsum(\"downgraded\").over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|max(downgrade_phase)|\n",
      "+--------------------+\n",
      "|                   3|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg( Fmax(col(\"downgrade_phase\")) ).show()\n",
    "\n",
    "# This is happening since there are users who downgraded multiple times. These users also upgraded multiple times. Hence the data here is not erroneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|level|        avg(count)|\n",
      "+-----+------------------+\n",
      "| free|215.33846153846153|\n",
      "| paid|1134.8597560975609|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.page == \"NextSong\").select([\"userId\", \"level\", \"ts\"]).groupby( [ \"level\", \"userId\" ] ).count().groupby(\"level\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|level|avgSongsPerSession|\n",
      "+-----+------------------+\n",
      "| free| 31.28982093144803|\n",
      "| paid|102.62525766710827|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of songs per session between paid and free\n",
    "\n",
    "#Lets first compute average number of songs per session for each user\n",
    "\n",
    "user_avg_songs_per_session = df.where(df.page == \"NextSong\") \\\n",
    "    .select([\"userId\", \"level\", \"sessionId\"]) \\\n",
    "    .groupby( [ \"level\", \"userId\", \"sessionId\" ] ).count() \\\n",
    "    .withColumnRenamed(\"count\", \"numSongsPerSession\") \\\n",
    "    .groupby( [ \"level\", \"userId\" ] ).agg( { \"numSongsPerSession\" : \"avg\"}) \\\n",
    "    .withColumnRenamed(\"avg(numSongsPerSession)\", \"avgSongsPerSession\")\n",
    "\n",
    "# Now lets average across all users for free and paid respectively\n",
    "user_avg_songs_per_session.groupby(\"level\").mean() \\\n",
    "    .withColumnRenamed(\"avg(avgSongsPerSession)\", \"avgSongsPerSession\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a stark difference. Since ads are played in the free tier, people might listen to lesser songs. Which also means if people dial down their usage due to some reason, then they might have a strong reason to hang on to the subscription. It is possible that people for whom the avg number of songs per session decreases beyond a point, there is a good chance of churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|level|    avgSongsPerDay|\n",
      "+-----+------------------+\n",
      "| free|32.318292019819815|\n",
      "| paid| 87.08996179115817|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of songs per day across free and paid\n",
    "\n",
    "# We first convert the timestamp to date ( in UTC ) and add it to the dataframe\n",
    "\n",
    "ts_date = udf(lambda x: datetime.datetime.utcfromtimestamp(x/1000), DateType() )\n",
    "df = df.withColumn(\"date\", ts_date(col(\"ts\")))\n",
    "\n",
    "#Compute number of songs per day per user\n",
    "\n",
    "user_avg_songs_per_day = df.where(df.page == \"NextSong\") \\\n",
    "    .select([\"userId\", \"level\", \"date\"]) \\\n",
    "    .groupby( [ \"level\", \"userId\", \"date\" ] ).count() \\\n",
    "    .withColumnRenamed(\"count\", \"numSongsPerDay\") \\\n",
    "    .groupby( [ \"level\", \"userId\" ] ).agg( { \"numSongsPerDay\" : \"avg\"}) \\\n",
    "    .withColumnRenamed(\"avg(numSongsPerDay)\", \"avgSongsPerDay\")\n",
    "\n",
    "# Now lets average across all users for free and paid respectively\n",
    "user_avg_songs_per_day.groupby(\"level\").mean() \\\n",
    "    .withColumnRenamed(\"avg(avgSongsPerDay)\", \"avgSongsPerDay\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+---------------------------+\n",
      "|max(pagenotfound_instances)|min(pagenotfound_instances)|\n",
      "+---------------------------+---------------------------+\n",
      "|                          7|                          1|\n",
      "+---------------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of 404s per user\n",
    "\n",
    "user_pagenotfound = df.filter(df.status == 404).select(\"userId\", \"status\", \"ts\").groupby(\"userId\").count().withColumnRenamed(\"count\", \"pagenotfound_instances\")\n",
    "\n",
    "user_pagenotfound.agg( Fmax(col(\"pagenotfound_instances\")), Fmin(col(\"pagenotfound_instances\"))  ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 404 errors in a span of 63 days seems a bit. Lets see what the distribution is like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|pagenotfound_instances|count|\n",
      "+----------------------+-----+\n",
      "|                     1|   49|\n",
      "|                     2|   32|\n",
      "|                     3|   20|\n",
      "|                     4|    8|\n",
      "|                     5|    4|\n",
      "|                     6|    1|\n",
      "|                     7|    3|\n",
      "+----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution of 404 instances\n",
    "\n",
    "user_pagenotfound.groupby(\"pagenotfound_instances\").count().sort(\"pagenotfound_instances\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amongst the few users who do see 404 errors, most of them see it only once. The number quickly drops after 3 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|max(error_instances)|min(error_instances)|\n",
      "+--------------------+--------------------+\n",
      "|                   7|                   1|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of errors per user\n",
    "\n",
    "user_error_pages = df.filter(df.page == \"Error\").select(\"userId\", \"status\", \"ts\").groupby(\"userId\").count().withColumnRenamed(\"count\", \"error_instances\")\n",
    "\n",
    "user_error_pages.agg( Fmax(col(\"error_instances\")), Fmin(col(\"error_instances\"))  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|error_instances|count|\n",
      "+---------------+-----+\n",
      "|              1|   49|\n",
      "|              2|   32|\n",
      "|              3|   20|\n",
      "|              4|    8|\n",
      "|              5|    4|\n",
      "|              6|    1|\n",
      "|              7|    3|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_error_pages.groupby(\"error_instances\").count().sort(\"error_instances\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that error and 404 instances have the same distribution. Its very likely that 404s are equivalent to errors. One could prove this using queries, but I will choose to accept this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thumbs up and thumbs down per user\n",
    "\n",
    "user_thumbsup_perday = df.filter(df.page == \"Thumbs Up\") \\\n",
    "    .select(\"userId\", \"date\") \\\n",
    "    .groupby( [ \"userId\", \"date\" ]) \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"thumbsup\") \\\n",
    "    .groupby(\"userId\").mean() \\\n",
    "    .withColumnRenamed(\"avg(thumbsup)\", \"avg_thumbsup_per_day\")\n",
    "    \n",
    "user_thumbsdown_perday = df.filter(df.page == \"Thumbs Down\") \\\n",
    "    .select(\"userId\", \"date\") \\\n",
    "    .groupby( [ \"userId\", \"date\" ]) \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"thumbsdown\") \\\n",
    "    .groupby(\"userId\").mean() \\\n",
    "    .withColumnRenamed(\"avg(thumbsdown)\", \"avg_thumbsdown_per_day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine user_avg_songs_per_day with user_thumbsup_perday and user_thumbsdown_perday to compute proportion of songs the user thumbs up's or down's. We will do this when we combine all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|max(help_visits)|min(help_visits)|\n",
      "+----------------+----------------+\n",
      "|              46|               1|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of help page visits\n",
    "\n",
    "user_help_vists = df.filter(df.page == \"Help\").select(\"userId\", \"status\", \"ts\").groupby(\"userId\").count().withColumnRenamed(\"count\", \"help_visits\")\n",
    "\n",
    "user_help_vists.agg( Fmax(col(\"help_visits\")), Fmin(col(\"help_visits\"))  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|help_visits|count|\n",
      "+-----------+-----+\n",
      "|          1|   34|\n",
      "|          2|   19|\n",
      "|          3|   15|\n",
      "|          4|   11|\n",
      "|          5|   13|\n",
      "|          6|   11|\n",
      "|          7|   18|\n",
      "|          8|    7|\n",
      "|          9|   14|\n",
      "|         10|    7|\n",
      "|         11|    2|\n",
      "|         12|    7|\n",
      "|         13|    5|\n",
      "|         14|    2|\n",
      "|         15|    5|\n",
      "|         16|    4|\n",
      "|         17|    2|\n",
      "|         18|    2|\n",
      "|         19|    3|\n",
      "|         20|    1|\n",
      "|         23|    2|\n",
      "|         24|    2|\n",
      "|         27|    1|\n",
      "|         28|    1|\n",
      "|         30|    1|\n",
      "|         34|    1|\n",
      "|         40|    1|\n",
      "|         46|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_help_vists.groupby(\"help_visits\").count().sort(\"help_visits\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of help visits is rather skewed towards lower numbers. People who have higher number of help page visits might have a higher propensity to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of friend referrals\n",
    "\n",
    "user_num_friends = df.select([\"userId\", \"page\"]) \\\n",
    "    .filter(df.page == \"Add Friend\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"numFriendAdditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract the data fetching from disk and basic cleanup into a function\n",
    "\n",
    "def obtain_data(filepath):\n",
    "    '''\n",
    "    Given a file path:\n",
    "    \n",
    "    1. Read the events json file\n",
    "    2. Remove records with null or empty string userId's and sessionId's\n",
    "    '''\n",
    "    df = spark.read.json(filepath=filepath)\n",
    "    df = df.where( (df.userId.isNotNull()) & (df.sessionId.isNotNull()) & (df.userId != \"\") & (df.sessionId != \"\") )\n",
    "    return df    \n",
    "\n",
    "# Combine all the feature engineering and put in a single function\n",
    "\n",
    "def feature_engineering(events_df):\n",
    "    '''\n",
    "    Given an events spark data frame, compute the necessary features for\n",
    "    predicting churn using machine learning algorithms\n",
    "    \n",
    "    Inputs:\n",
    "        events_df: Spark data frame with the structure        \n",
    "         |-- artist: string (nullable = true)\n",
    "         |-- auth: string (nullable = true)\n",
    "         |-- firstName: string (nullable = true)\n",
    "         |-- gender: string (nullable = true)\n",
    "         |-- itemInSession: long (nullable = true)\n",
    "         |-- lastName: string (nullable = true)\n",
    "         |-- length: double (nullable = true)\n",
    "         |-- level: string (nullable = true)\n",
    "         |-- location: string (nullable = true)\n",
    "         |-- method: string (nullable = true)\n",
    "         |-- page: string (nullable = true)\n",
    "         |-- registration: long (nullable = true)\n",
    "         |-- sessionId: long (nullable = true)\n",
    "         |-- song: string (nullable = true)\n",
    "         |-- status: long (nullable = true)\n",
    "         |-- ts: long (nullable = true)\n",
    "         |-- userAgent: string (nullable = true)\n",
    "         |-- userId: string (nullable = true)            \n",
    "    \n",
    "    Output:\n",
    "        df_feature: Spark data frame with the following structure\n",
    "        root\n",
    "         |-- userId: string (nullable = true)\n",
    "         |-- downgraded: integer (nullable = true)\n",
    "         |-- cancelled: integer (nullable = true)\n",
    "         |-- avgSongsPerSession: double (nullable = true)\n",
    "         |-- avgSongsPerDay: double (nullable = true)\n",
    "         |-- avg_thumbsup_per_day: double (nullable = true)\n",
    "         |-- avg_thumbsup_per_day: double (nullable = true)\n",
    "         |-- error_instances: long (nullable = false)\n",
    "         |-- help_visits: long (nullable = false)\n",
    "         |-- numFriendAdditions: long (nullable = false)\n",
    "    '''\n",
    "    \n",
    "    churn = udf(lambda x: int(x == 'Cancellation Confirmation'), IntegerType())\n",
    "    downgrade_churn = udf(lambda x: int(x == 'Submit Downgrade'), IntegerType())    \n",
    "    signum = udf(lambda x: int(x>0), IntegerType())\n",
    "    ts_date = udf(lambda x: datetime.datetime.utcfromtimestamp(x/1000), DateType() )\n",
    "    proportion = udf(lambda x,y : x/y, FloatType())\n",
    "    \n",
    "    ## Base transformations to input df\n",
    "    events_df = events_df.withColumn(\"date\", ts_date(col(\"ts\")))       \n",
    "       \n",
    "    ## User level features    \n",
    "    \n",
    "    # Status of each user ( target variable )\n",
    "    user_status = events_df.select([\"userId\", \"downgraded\", \"cancelled\"]) \\\n",
    "        .groupby(\"userId\").sum() \\\n",
    "        .withColumnRenamed(\"sum(downgraded)\" , \"sum_downgraded\") \\\n",
    "        .withColumnRenamed(\"sum(cancelled)\" , \"sum_cancelled\") \\\n",
    "\n",
    "    user_status = user_status \\\n",
    "        .withColumn('downgraded', signum(col(\"sum_downgraded\"))) \\\n",
    "        .withColumn('cancelled', signum(col(\"sum_cancelled\"))) \\\n",
    "        .drop('sum_downgraded').drop('sum_cancelled')\n",
    "    # The signum function is used since there are users who have multiple downgrade events.\n",
    "        \n",
    "    #Number of songs per session per user\n",
    "    user_avg_songs_per_session = events_df.where(events_df.page == \"NextSong\") \\\n",
    "        .select([\"userId\", \"sessionId\"]) \\\n",
    "        .groupby( [ \"userId\", \"sessionId\" ] ).count() \\\n",
    "        .withColumnRenamed(\"count\", \"numSongsPerSession\") \\\n",
    "        .groupby( [ \"userId\" ] ).agg( { \"numSongsPerSession\" : \"avg\"}) \\\n",
    "        .withColumnRenamed(\"avg(numSongsPerSession)\", \"avgSongsPerSession\")\n",
    "    \n",
    "    #Number of songs per day per user\n",
    "    user_avg_songs_per_day = events_df.where(events_df.page == \"NextSong\") \\\n",
    "        .select([\"userId\", \"date\"]) \\\n",
    "        .groupby( [ \"userId\", \"date\" ] ).count() \\\n",
    "        .withColumnRenamed(\"count\", \"numSongsPerDay\") \\\n",
    "        .groupby( [ \"userId\" ] ).agg( { \"numSongsPerDay\" : \"avg\"}) \\\n",
    "        .withColumnRenamed(\"avg(numSongsPerDay)\", \"avgSongsPerDay\")\n",
    "    \n",
    "    #Number of thumbs ups per day per user\n",
    "    user_thumbsup_perday = events_df.filter(events_df.page == \"Thumbs Up\") \\\n",
    "        .select(\"userId\", \"date\") \\\n",
    "        .groupby( [ \"userId\", \"date\" ]) \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"thumbsup\") \\\n",
    "        .groupby(\"userId\").mean() \\\n",
    "        .withColumnRenamed(\"avg(thumbsup)\", \"avg_thumbsup_per_day\")\n",
    "    \n",
    "    #Number of thumbs down per day per user\n",
    "    user_thumbsdown_perday = events_df.filter(events_df.page == \"Thumbs Down\") \\\n",
    "        .select(\"userId\", \"date\") \\\n",
    "        .groupby( [ \"userId\", \"date\" ]) \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"thumbsdown\") \\\n",
    "        .groupby(\"userId\").mean() \\\n",
    "        .withColumnRenamed(\"avg(thumbsdown)\", \"avg_thumbsdown_per_day\")    \n",
    "\n",
    "    #Number of error pages encountered by user\n",
    "    user_error_pages = events_df.filter(events_df.page == \"Error\") \\\n",
    "        .select(\"userId\", \"status\", \"ts\") \\\n",
    "        .groupby(\"userId\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"error_instances\")\n",
    "    \n",
    "    # Number of help page visits\n",
    "    user_help_vists = events_df.filter(events_df.page == \"Help\") \\\n",
    "        .select(\"userId\", \"status\", \"ts\") \\\n",
    "        .groupby(\"userId\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"help_visits\")\n",
    "    \n",
    "    # Number of friend additions per user\n",
    "    user_num_friends = events_df.select([\"userId\", \"page\"]) \\\n",
    "        .filter(df.page == \"Add Friend\") \\\n",
    "        .groupby(\"userId\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"numFriendAdditions\")\n",
    "    \n",
    "    df_features = user_status \\\n",
    "        .join(user_avg_songs_per_session, on = \"userId\" , how = 'left') \\\n",
    "        .join(user_avg_songs_per_day, on = \"userId\", how = 'left') \\\n",
    "        .join(user_thumbsup_perday, on = \"userId\", how = 'left') \\\n",
    "        .join(user_thumbsdown_perday, on = \"userId\", how = 'left') \\\n",
    "        .join(user_error_pages, on = \"userId\", how = 'left') \\\n",
    "        .join(user_help_vists, on = \"userId\", how = 'left') \\\n",
    "        .join(user_num_friends, on = \"userId\", how = 'left')\n",
    "    \n",
    "    # Renaming the target column to label and casting it to DoubleType\n",
    "    df_features = df_features.withColumn( \"label\", df_features.cancelled.cast(DoubleType())).drop(\"cancelled\")\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------+------------------+--------------------+----------------------+---------------+-----------+------------------+-----+\n",
      "|userId|downgraded|avgSongsPerSession|    avgSongsPerDay|avg_thumbsup_per_day|avg_thumbsdown_per_day|error_instances|help_visits|numFriendAdditions|label|\n",
      "+------+----------+------------------+------------------+--------------------+----------------------+---------------+-----------+------------------+-----+\n",
      "|100010|         0|39.285714285714285|39.285714285714285|  2.8333333333333335|                  1.25|           null|          2|                 4|  0.0|\n",
      "|200002|         0|              64.5|55.285714285714285|                 3.0|                   3.0|           null|          2|                 4|  0.0|\n",
      "|   125|         0|               8.0|               8.0|                null|                  null|           null|       null|              null|  1.0|\n",
      "|    51|         0|             211.1| 162.3846153846154|   8.333333333333334|                   2.1|              1|         12|                28|  1.0|\n",
      "|   124|         0|145.67857142857142|         127.46875|   5.896551724137931|    1.8636363636363635|              6|         23|                74|  0.0|\n",
      "|     7|         0|21.428571428571427|             18.75|                1.75|                   1.0|              1|          1|                 1|  0.0|\n",
      "|    54|         1| 81.17142857142858|              94.7|   6.037037037037037|    1.5263157894736843|              1|         17|                33|  1.0|\n",
      "|    15|         0|136.71428571428572|100.73684210526316|                 5.4|                   1.4|              2|          8|                31|  0.0|\n",
      "|   155|         0|136.66666666666666|             102.5|   8.285714285714286|                   1.0|              3|          9|                11|  0.0|\n",
      "|   132|         0|             120.5| 91.80952380952381|   5.333333333333333|                   1.7|              3|         16|                41|  0.0|\n",
      "+------+----------+------------------+------------------+--------------------+----------------------+---------------+-----------+------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- downgraded: integer (nullable = true)\n",
      " |-- avgSongsPerSession: double (nullable = true)\n",
      " |-- avgSongsPerDay: double (nullable = true)\n",
      " |-- avg_thumbsup_per_day: double (nullable = true)\n",
      " |-- avg_thumbsdown_per_day: double (nullable = true)\n",
      " |-- error_instances: long (nullable = true)\n",
      " |-- help_visits: long (nullable = true)\n",
      " |-- numFriendAdditions: long (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(df_features):\n",
    "    feature_cols = df_features.drop('userId', 'label').columns\n",
    "    #Replace nulls with zero for columns in feature_cols\n",
    "    df_features = df_features.fillna(0, subset = feature_cols )\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"FeatureVector\")\n",
    "    df_features = assembler.transform(df_features)\n",
    "    \n",
    "    scaler = StandardScaler(withMean = True, inputCol = \"FeatureVector\",  outputCol = \"ScaledFeatureVector\")\n",
    "    scalerModel = scaler.fit(df_features)\n",
    "    df_features = scalerModel.transform(df_features)\n",
    "    df_features_scaled = df_features.select([\"userId\", \"label\", \"ScaledFeatureVector\"])    \n",
    "    \n",
    "    return df_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_scaled = feature_scaling(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, label: double, ScaledFeatureVector: vector]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_scaled.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userId|label|ScaledFeatureVector                                                                                                                                              |\n",
      "+------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|100010|0.0  |[-0.5264710031632485,-0.7392637500378801,-0.783710508690406,-0.7321501459351433,-0.36390803366118396,-0.7605559300887401,-0.6161090451316099,-0.7292340618073143]|\n",
      "|200002|0.0  |[-0.5264710031632485,-0.14759257929335814,-0.2848591481704853,-0.6465812558359041,1.8888671790512386,-0.7605559300887401,-0.6161090451316099,-0.7292340618073143]|\n",
      "|125   |1.0  |[-0.5264710031632485,-1.473405316004171,-1.7591430797070366,-2.1868212776222102,-1.9730331855986287,-0.7605559300887401,-0.892253537471475,-0.9235813095498617]  |\n",
      "|51    |1.0  |[-0.5264710031632485,3.292480822508503,3.0542928845404678,2.0916232273397517,0.7302970696562785,-0.08148813536665052,0.764613416567715,0.4368494246479705]       |\n",
      "|124   |0.0  |[-0.5264710031632485,1.7573204109365261,1.965678700112606,0.8405470410612189,0.4260261318353797,3.3138508382437974,2.2834081244369724,2.6718427736872665]        |\n",
      "|7     |0.0  |[-0.5264710031632485,-1.158294324219553,-1.423977321857715,-1.2883479315801984,-0.685733064048673,-0.08148813536665052,-0.7541812913015424,-0.8749944976142249]  |\n",
      "|54    |1.0  |[1.8909978889128924,0.24361436476265175,0.9440077301102838,0.9126740748613443,-0.008206684285538196,-0.08148813536665052,1.4549746474173773,0.6797834843261549]  |\n",
      "|15    |0.0  |[-0.5264710031632485,1.5469670626973269,1.1322256612011883,0.5856107615931411,-0.17081301542869073,0.597579659355439,0.21232443188798503,0.5826098604548812]     |\n",
      "|155   |0.0  |[-0.5264710031632485,1.545849647832842,1.1871977683637451,2.0671749730256836,-0.685733064048673,1.2766474540775286,0.3503966780579175,-0.38912637825785623]      |\n",
      "|132   |0.0  |[-0.5264710031632485,1.1664873013403678,0.853887856349691,0.551383205553445,0.21537702103629605,1.2766474540775286,1.3169024012474448,1.0684779798112498]        |\n",
      "+------+-----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features_scaled.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_scaled.count()\n",
    "\n",
    "# We have a row for each user in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = df_features_scaled.randomSplit([0.70, 0.30], seed = 42)\n",
    "# test, validation = rest.randomSplit([0.50, 0.50], seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the distribution of churned an non-churned users in both the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  127|\n",
      "|  1.0|   36|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|   46|\n",
      "|  1.0|   16|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both datasets about 22-25% of the users have churned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for find the best threshold and evaluating a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_by_f1_score(preds, labelCol = 'label', probabilityCol = 'probability', steps = 1000):\n",
    "    '''\n",
    "        Given prediction probabilities by a classiification model, find the best threshold that maximizes fscore\n",
    "        \n",
    "        Input:\n",
    "            preds - Spark dataframe with the following schema            \n",
    "             |-- userId: string (nullable = true)\n",
    "             |-- label: double (nullable = true)\n",
    "             |-- ScaledFeatureVector: vector (nullable = true)\n",
    "             |-- rawPrediction: vector (nullable = true)\n",
    "             |-- probability: vector (nullable = true)\n",
    "             |-- prediction: double (nullable = false)\n",
    "        \n",
    "        Output:\n",
    "            best_threshold - Best threshold in [0,1] that maximizes fscore\n",
    "            best_fscore - Best fscore achieved using the best_threshold\n",
    "    '''\n",
    "    labels = preds[labelCol]\n",
    "    probability = preds[probabilityCol]\n",
    "    fscores = []\n",
    "    thresholds = np.linspace(0,1,steps)\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        pred_labels = probability.apply(lambda x: np.float64(x > thresh))\n",
    "        fscores.append( f1_score(labels, pred_labels) )\n",
    "    \n",
    "    return ( thresholds[ np.argmax(fscores) ], np.max(fscores) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train, validation):\n",
    "    '''\n",
    "    Input:\n",
    "        ML model after fitting\n",
    "        \n",
    "        Given a model we find the best threshold that gives the best f-score on the valdation data set\n",
    "        Then we take this best threshold and apply that on the model predictions of the test data set.\n",
    "        On this set set of predictions on the test set we compute precision, recall, f-score etc.\n",
    "        \n",
    "        We also compute area under the ROC curve for train, validation and test datasets\n",
    "    \n",
    "    Output:\n",
    "        Metrics:\n",
    "            AUC for train, validation and test            \n",
    "            Best threshold based on validation\n",
    "            FScore using best threshold on validation, test            \n",
    "    '''\n",
    "    \n",
    "    model_preds_train = model.transform(train)\n",
    "    model_preds_valid = model.transform(validation)\n",
    "    \n",
    "    evaluator_roc = BinaryClassificationEvaluator(metricName = 'areaUnderROC')\n",
    "    auc_train = evaluator_roc.evaluate(model_preds_train)\n",
    "    auc_valid = evaluator_roc.evaluate(model_preds_valid)\n",
    "    \n",
    "    model_preds_train_df = model_preds_train.select( [ 'userId', 'label', 'probability', 'prediction' ] ).toPandas()\n",
    "    \n",
    "    model_train_fscore = f1_score( model_preds_train_df.label, model_preds_train_df.prediction)\n",
    "    model_train_precision = precision_score( model_preds_train_df.label, model_preds_train_df.prediction)\n",
    "    model_train_recall = recall_score( model_preds_train_df.label, model_preds_train_df.prediction)\n",
    "    model_train_accuracy = accuracy_score( model_preds_train_df.label, model_preds_train_df.prediction)\n",
    "    \n",
    "    model_preds_valid_df = model_preds_valid.select( [ 'userId', 'label', 'probability', 'prediction' ] ).toPandas()  \n",
    "    \n",
    "    model_valid_fscore = f1_score( model_preds_valid_df.label, model_preds_valid_df.prediction)\n",
    "    model_valid_precision = precision_score( model_preds_valid_df.label, model_preds_valid_df.prediction)\n",
    "    model_valid_recall = recall_score( model_preds_valid_df.label, model_preds_valid_df.prediction)\n",
    "    model_valid_accuracy = accuracy_score( model_preds_valid_df.label, model_preds_valid_df.prediction)    \n",
    "    \n",
    "    metrics = {\n",
    "        'train_auc' : auc_train,\n",
    "        'valid_auc' : auc_valid,        \n",
    "        'train_precision' : model_train_precision,\n",
    "        'train_recall' : model_train_recall,\n",
    "        'train_fscore' : model_train_fscore,\n",
    "        'train_accuracy': model_train_accuracy,        \n",
    "        'valid_precision' : model_valid_precision,\n",
    "        'valid_recall' : model_valid_recall,\n",
    "        'valid_fscore' : model_valid_fscore,\n",
    "        'valid_accuracy': model_valid_accuracy\n",
    "    }\n",
    "    \n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 172 ms, sys: 56 ms, total: 228 ms\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random forest classifier\n",
    "rf = RandomForestClassifier(\n",
    "        featuresCol = \"ScaledFeatureVector\", \n",
    "        labelCol = 'label', \n",
    "        maxMemoryInMB = 1000, \n",
    "        seed = 42\n",
    "    )\n",
    "rf_model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- ScaledFeatureVector: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model.transform(train).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_metrics = evaluate_model(rf_model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_auc': 0.9857830271216097,\n",
       " 'valid_auc': 0.6671195652173915,\n",
       " 'train_precision': 1.0,\n",
       " 'train_recall': 0.4166666666666667,\n",
       " 'train_fscore': 0.5882352941176471,\n",
       " 'train_accuracy': 0.8711656441717791,\n",
       " 'valid_precision': 1.0,\n",
       " 'valid_recall': 0.125,\n",
       " 'valid_fscore': 0.2222222222222222,\n",
       " 'valid_accuracy': 0.7741935483870968}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.41 s, sys: 724 ms, total: 3.14 s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Gradient boosted trees classifier\n",
    "gbt = GBTClassifier(\n",
    "        featuresCol = \"ScaledFeatureVector\", \n",
    "        labelCol = 'label', \n",
    "        maxMemoryInMB = 1000, \n",
    "        seed = 42,\n",
    "    )\n",
    "gbt_model = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model_metrics = evaluate_model(gbt_model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_auc': 0.9997812773403325,\n",
       " 'valid_auc': 0.7472826086956519,\n",
       " 'train_precision': 1.0,\n",
       " 'train_recall': 0.9722222222222222,\n",
       " 'train_fscore': 0.9859154929577464,\n",
       " 'train_accuracy': 0.9938650306748467,\n",
       " 'valid_precision': 0.6,\n",
       " 'valid_recall': 0.375,\n",
       " 'valid_fscore': 0.4615384615384615,\n",
       " 'valid_accuracy': 0.7741935483870968}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 500 ms, sys: 128 ms, total: 628 ms\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(featuresCol = \"ScaledFeatureVector\")\n",
    "lr_model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_metrics = evaluate_model(lr_model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_auc': 0.8018372703412077,\n",
       " 'valid_auc': 0.6480978260869564,\n",
       " 'train_precision': 0.625,\n",
       " 'train_recall': 0.2777777777777778,\n",
       " 'train_fscore': 0.3846153846153846,\n",
       " 'train_accuracy': 0.803680981595092,\n",
       " 'valid_precision': 0.5,\n",
       " 'valid_recall': 0.125,\n",
       " 'valid_fscore': 0.2,\n",
       " 'valid_accuracy': 0.7419354838709677}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all these models we can observe heavy overfitting. The train AUC's are very close to 1 while the validation and test AUCs are closer to 0.5\n",
    "\n",
    "Lets tune the parameters of the models and try to reduce the overfitting using cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.11 s, sys: 1.54 s, total: 6.65 s\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random forest with cross validation\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5,10,20]) \\\n",
    "    .addGrid( rf.minInstancesPerNode, [5, 10, 20] ) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(metricName = 'areaUnderROC'),\n",
    "                          numFolds=3)\n",
    "rf_cv_model = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karthikv/programming/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/karthikv/programming/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rf_cv_model_metrics = evaluate_model(rf_cv_model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_auc': 0.7725284339457572,\n",
       " 'valid_auc': 0.688858695652174,\n",
       " 'train_precision': 0.0,\n",
       " 'train_recall': 0.0,\n",
       " 'train_fscore': 0.0,\n",
       " 'train_accuracy': 0.7791411042944786,\n",
       " 'valid_precision': 0.0,\n",
       " 'valid_recall': 0.0,\n",
       " 'valid_fscore': 0.0,\n",
       " 'valid_accuracy': 0.7419354838709677}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_dab8a114eff7', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'auto',\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='featuresCol', doc='features column name'): 'ScaledFeatureVector',\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='labelCol', doc='label column name'): 'label',\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 1000,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 20,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='numTrees', doc='Number of trees to train (>= 1)'): 20,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability',\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='seed', doc='random seed'): 42,\n",
       " Param(parent='RandomForestClassifier_dab8a114eff7', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what parameters the best model took\n",
    "\n",
    "rf_cv_model.bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosted tree classifier with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.4 s, sys: 12.2 s, total: 48.5 s\n",
      "Wall time: 35min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Gradient boosted trees with cross validation\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5,10]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [5, 15] ) \\\n",
    "    .build()\n",
    "\n",
    "gbt_crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=gbt_paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(metricName = 'areaUnderROC'),\n",
    "                          numFolds=3)\n",
    "\n",
    "gbt_cv_model = gbt_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_cv_model_metrics = evaluate_model(gbt_cv_model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_auc': 0.9993438320209973,\n",
       " 'valid_auc': 0.6168478260869564,\n",
       " 'train_precision': 1.0,\n",
       " 'train_recall': 0.9444444444444444,\n",
       " 'train_fscore': 0.9714285714285714,\n",
       " 'train_accuracy': 0.9877300613496932,\n",
       " 'valid_precision': 0.5714285714285714,\n",
       " 'valid_recall': 0.25,\n",
       " 'valid_fscore': 0.34782608695652173,\n",
       " 'valid_accuracy': 0.7580645161290323}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_cv_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='GBTClassifier_68f407fe1214', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'all',\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='featuresCol', doc='features column name'): 'ScaledFeatureVector',\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='labelCol', doc='label column name'): 'label',\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='lossType', doc='Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic'): 'logistic',\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='maxIter', doc='maximum number of iterations (>= 0)'): 20,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 1000,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='seed', doc='random seed'): 42,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1,\n",
       " Param(parent='GBTClassifier_68f407fe1214', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see what the best models parameters\n",
    "gbt_cv_model.bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression  with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 3.87 s, total: 15 s\n",
      "Wall time: 7min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression with cross validation\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.0, 0.1, 0.5, 1.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.05, 0.1] ) \\\n",
    "    .build()\n",
    "\n",
    "lr_crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(metricName = 'areaUnderROC'),\n",
    "                          numFolds=3)\n",
    "\n",
    "lr_cv_model = lr_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_model_metrics = evaluate_model(lr_cv_model, train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_auc': 0.8018372703412077,\n",
       " 'valid_auc': 0.6480978260869564,\n",
       " 'train_precision': 0.625,\n",
       " 'train_recall': 0.2777777777777778,\n",
       " 'train_fscore': 0.3846153846153846,\n",
       " 'train_accuracy': 0.803680981595092,\n",
       " 'valid_precision': 0.5,\n",
       " 'valid_recall': 0.125,\n",
       " 'valid_fscore': 0.2,\n",
       " 'valid_accuracy': 0.7419354838709677}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base RF</th>\n",
       "      <th>CV RF</th>\n",
       "      <th>Base GBT</th>\n",
       "      <th>CV GBT</th>\n",
       "      <th>Base LR</th>\n",
       "      <th>CV LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.871166</td>\n",
       "      <td>0.779141</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.987730</td>\n",
       "      <td>0.803681</td>\n",
       "      <td>0.803681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc</th>\n",
       "      <td>0.985783</td>\n",
       "      <td>0.772528</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.801837</td>\n",
       "      <td>0.801837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_fscore</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_accuracy</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_auc</th>\n",
       "      <td>0.667120</td>\n",
       "      <td>0.688859</td>\n",
       "      <td>0.747283</td>\n",
       "      <td>0.616848</td>\n",
       "      <td>0.648098</td>\n",
       "      <td>0.648098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_fscore</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_recall</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Base RF     CV RF  Base GBT    CV GBT   Base LR     CV LR\n",
       "train_accuracy   0.871166  0.779141  0.993865  0.987730  0.803681  0.803681\n",
       "train_auc        0.985783  0.772528  0.999781  0.999344  0.801837  0.801837\n",
       "train_fscore     0.588235  0.000000  0.985915  0.971429  0.384615  0.384615\n",
       "train_precision  1.000000  0.000000  1.000000  1.000000  0.625000  0.625000\n",
       "train_recall     0.416667  0.000000  0.972222  0.944444  0.277778  0.277778\n",
       "valid_accuracy   0.774194  0.741935  0.774194  0.758065  0.741935  0.741935\n",
       "valid_auc        0.667120  0.688859  0.747283  0.616848  0.648098  0.648098\n",
       "valid_fscore     0.222222  0.000000  0.461538  0.347826  0.200000  0.200000\n",
       "valid_precision  1.000000  0.000000  0.600000  0.571429  0.500000  0.500000\n",
       "valid_recall     0.125000  0.000000  0.375000  0.250000  0.125000  0.125000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = pd.DataFrame( { \n",
    "    'Base RF': rf_model_metrics, \n",
    "    'CV RF' : rf_cv_model_metrics, \n",
    "    'Base GBT' : gbt_model_metrics, \n",
    "    'CV GBT' : gbt_cv_model_metrics,\n",
    "    'Base LR' : lr_model_metrics,\n",
    "    'CV LR' : lr_cv_model_metrics\n",
    "}).sort_index()\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model\n",
    "\n",
    "The base GBT is the best performing model when comparing using validation fscore.\n",
    "\n",
    "One common thing noticeable across all models is that they have high precision but rather low recall. In this context, it means if the model predicts a user will churn, then its very likely the user will churn indeed. Poor recall on the other hand if a user were to churn then the model may not predict that the user would churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current model has high precision but poor recall. Increasing recall is certainly an area for improvement. High precision is useful since likely an organization will spend some money to incentivize the people whom the model predicts will leave. Hence having high precision will ensure the organization's capital is used effectively. However poor recall will imply many users will churn without the organization predicting upfront. This would lead to a loss in the user base and decreased revenue.\n",
    "\n",
    "On the feature development part many more things could be done. Some potential feature additions are:\n",
    "\n",
    "1. Current level of a user\n",
    "<br>Is the user a paid or a free user. Given paid users seem to churn more, this could be an interesting feature\n",
    "2. Has the user downgraded/upgraded in the past, how many times\n",
    "3. Time since upgrade\n",
    "4. Number of additions to playlist\n",
    "5. Number of advertisement roll outs\n",
    "6. Average time spent in a session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
